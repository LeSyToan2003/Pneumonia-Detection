{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f403f056",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import zipfile\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import InputLayer, Conv2D, MaxPool2D\n",
    "from keras.layers import Flatten, GlobalAveragePooling2D, GlobalMaxPooling2D, Concatenate\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.saving import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbb5405",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    keras.utils.set_random_seed(seed)\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = \"42\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78005b88",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16cf424",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def fdr(y_true, y_pred):\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    \n",
    "    fdr_ = FP / (FP + TP) if (FP + TP) > 0 else 0\n",
    "    \n",
    "    return fdr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a14a1a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def fnr(y_true, y_pred):\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    \n",
    "    fnr_ = FN / (FN + TP) if (FN + TP) > 0 else 0\n",
    "    \n",
    "    return fnr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d63f959",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def specificity(y_true, y_pred):\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    \n",
    "    specificity_ = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    \n",
    "    return specificity_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec3fff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def npv(y_true, y_pred):\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    npv_ = TN / (TN + FN) if (TN + FN) > 0 else 0\n",
    "    \n",
    "    return npv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce2cd7b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_cxr = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/train/cxr.csv')\n",
    "train_ch0 = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/train/segment.csv')\n",
    "train_ch1 = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/train/segment_with_convexhull.csv')\n",
    "\n",
    "test_cxr = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/test/cxr.csv')\n",
    "test_ch0 = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/test/segment.csv')\n",
    "test_ch1 = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/test/segment_with_convexhull.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26359821",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "x_train_cxr = train_cxr.drop(['class'], axis=1).to_numpy()\n",
    "x_train_ch0 = train_ch0.drop(['class'], axis=1).to_numpy()\n",
    "x_train_ch1 = train_ch1.drop(['class'], axis=1).to_numpy()\n",
    "y_train = train_cxr['class'].to_numpy()\n",
    "\n",
    "x_test_cxr = test_cxr.drop(['class'], axis=1).to_numpy()\n",
    "x_test_ch0 = test_ch0.drop(['class'], axis=1).to_numpy()\n",
    "x_test_ch1 = test_ch1.drop(['class'], axis=1).to_numpy()\n",
    "y_test = test_cxr['class'].to_numpy()\n",
    "\n",
    "print(np.shape(x_train_cxr))\n",
    "print(np.shape(x_train_ch0))\n",
    "print(np.shape(x_train_ch1))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_test_cxr))\n",
    "print(np.shape(x_test_ch0))\n",
    "print(np.shape(x_test_ch1))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a69e0ac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "indices_0 = np.where(y_train == 0)[0]\n",
    "indices_1 = np.where(y_train == 1)[0]\n",
    "\n",
    "random_seed(42)\n",
    "random_indices_0 = np.random.choice(indices_0, size=250, replace=0)\n",
    "random_indices_1 = np.random.choice(indices_1, size=350, replace=0)\n",
    "random_indices = np.concatenate((random_indices_0, random_indices_1), axis=0)\n",
    "\n",
    "x_val_cxr = x_train_cxr[random_indices]\n",
    "x_val_ch0 = x_train_ch0[random_indices]\n",
    "x_val_ch1 = x_train_ch1[random_indices]\n",
    "y_val = y_train[random_indices]\n",
    "\n",
    "x_train_cxr = np.delete(x_train_cxr, random_indices, axis=0)\n",
    "x_train_ch0 = np.delete(x_train_ch0, random_indices, axis=0)\n",
    "x_train_ch1 = np.delete(x_train_ch1, random_indices, axis=0)\n",
    "y_train = np.delete(y_train, random_indices, axis=0)\n",
    "\n",
    "print(np.shape(x_train_cxr))\n",
    "print(np.shape(x_train_ch0))\n",
    "print(np.shape(x_train_ch1))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_val_cxr))\n",
    "print(np.shape(x_val_ch0))\n",
    "print(np.shape(x_val_ch1))\n",
    "print(np.shape(y_val))\n",
    "print(np.shape(x_test_cxr))\n",
    "print(np.shape(x_test_ch0))\n",
    "print(np.shape(x_test_ch1))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b67ce3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(classes, class_weights)}\n",
    "\n",
    "print(class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa22f035",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)\n",
    "\n",
    "print(np.shape(x_train_cxr))\n",
    "print(np.shape(x_train_ch0))\n",
    "print(np.shape(x_train_ch1))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_val_cxr))\n",
    "print(np.shape(x_val_ch0))\n",
    "print(np.shape(x_val_ch1))\n",
    "print(np.shape(y_val))\n",
    "print(np.shape(x_test_cxr))\n",
    "print(np.shape(x_test_ch0))\n",
    "print(np.shape(x_test_ch1))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e584c91",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "random_seed(42)\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(shape=(8192,)),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=4e-6),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train_cxr, \n",
    "    y=y_train,\n",
    "    validation_data=(x_val_cxr, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "y_pred = model.predict(x_test_cxr, verbose=False)\n",
    "y_pred = np.argmax(y_pred, axis=1).reshape(-1)\n",
    "\n",
    "print('accuracy = {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('precision = {}'.format(precision_score(y_test, y_pred)))\n",
    "print('FDR = {}'.format(fdr(y_test, y_pred)))\n",
    "print('recall = {}'.format(recall_score(y_test, y_pred)))\n",
    "print('FNR = {}'.format(fnr(y_test, y_pred)))\n",
    "print('specificity = {}'.format(specificity(y_test, y_pred)))\n",
    "print('NPV = {}'.format(npv(y_test, y_pred)))\n",
    "print('f1-score = {}'.format(f1_score(y_test, y_pred)))\n",
    "print('AUC = {}'.format(roc_auc_score(y_test, y_pred)))\n",
    "print('MCC = {}'.format(matthews_corrcoef(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af972c35",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "random_seed(42)\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(shape=(8192,)),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=4e-6),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train_ch0, \n",
    "    y=y_train,\n",
    "    validation_data=(x_val_ch0, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "y_pred = model.predict(x_test_ch0, verbose=False)\n",
    "y_pred = np.argmax(y_pred, axis=1).reshape(-1)\n",
    "\n",
    "print('accuracy = {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('precision = {}'.format(precision_score(y_test, y_pred)))\n",
    "print('FDR = {}'.format(fdr(y_test, y_pred)))\n",
    "print('recall = {}'.format(recall_score(y_test, y_pred)))\n",
    "print('FNR = {}'.format(fnr(y_test, y_pred)))\n",
    "print('specificity = {}'.format(specificity(y_test, y_pred)))\n",
    "print('NPV = {}'.format(npv(y_test, y_pred)))\n",
    "print('f1-score = {}'.format(f1_score(y_test, y_pred)))\n",
    "print('AUC = {}'.format(roc_auc_score(y_test, y_pred)))\n",
    "print('MCC = {}'.format(matthews_corrcoef(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa02bfc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "random_seed(42)\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(shape=(8192,)),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=4e-6),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train_ch1, \n",
    "    y=y_train,\n",
    "    validation_data=(x_val_ch1, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "y_pred = model.predict(x_test_ch1, verbose=False)\n",
    "y_pred = np.argmax(y_pred, axis=1).reshape(-1)\n",
    "\n",
    "print('accuracy = {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('precision = {}'.format(precision_score(y_test, y_pred)))\n",
    "print('FDR = {}'.format(fdr(y_test, y_pred)))\n",
    "print('recall = {}'.format(recall_score(y_test, y_pred)))\n",
    "print('FNR = {}'.format(fnr(y_test, y_pred)))\n",
    "print('specificity = {}'.format(specificity(y_test, y_pred)))\n",
    "print('NPV = {}'.format(npv(y_test, y_pred)))\n",
    "print('f1-score = {}'.format(f1_score(y_test, y_pred)))\n",
    "print('AUC = {}'.format(roc_auc_score(y_test, y_pred)))\n",
    "print('MCC = {}'.format(matthews_corrcoef(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
