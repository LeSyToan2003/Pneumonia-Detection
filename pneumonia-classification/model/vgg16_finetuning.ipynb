{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39830916",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import zipfile\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import VGG16\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import InputLayer, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.saving import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcaeb1a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    keras.utils.set_random_seed(seed)\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = \"42\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8244afa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e349e108",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def fdr(y_true, y_pred):\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    \n",
    "    fdr_ = FP / (FP + TP) if (FP + TP) > 0 else 0\n",
    "    \n",
    "    return fdr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7a7438",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def fnr(y_true, y_pred):\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    \n",
    "    fnr_ = FN / (FN + TP) if (FN + TP) > 0 else 0\n",
    "    \n",
    "    return fnr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21be603e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def specificity(y_true, y_pred):\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    \n",
    "    specificity_ = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    \n",
    "    return specificity_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e767ae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def npv(y_true, y_pred):\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    npv_ = TN / (TN + FN) if (TN + FN) > 0 else 0\n",
    "    \n",
    "    return npv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e09cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f645ba4d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "x_train_cxr = np.load('/kaggle/input/pneumonia-detection-datasets/chest-xray/train/images.npy')\n",
    "x_train_ch0 = np.load('/kaggle/input/pneumonia-detection-datasets/segment/train/images.npy')\n",
    "x_train_ch1 = np.load('/kaggle/input/pneumonia-detection-datasets/segment_with_convexhull/train/images.npy')\n",
    "y_train = np.load('/kaggle/input/pneumonia-detection-datasets/chest-xray/train/labels.npy')\n",
    "\n",
    "x_test_cxr = np.load('/kaggle/input/pneumonia-detection-datasets/chest-xray/test/images.npy')\n",
    "x_test_ch0 = np.load('/kaggle/input/pneumonia-detection-datasets/segment/test/images.npy')\n",
    "x_test_ch1 = np.load('/kaggle/input/pneumonia-detection-datasets/segment_with_convexhull/test/images.npy')\n",
    "y_test = np.load('/kaggle/input/pneumonia-detection-datasets/chest-xray/test/labels.npy')\n",
    "\n",
    "print(np.shape(x_train_cxr))\n",
    "print(np.shape(x_train_ch0))\n",
    "print(np.shape(x_train_ch1))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_test_cxr))\n",
    "print(np.shape(x_test_ch0))\n",
    "print(np.shape(x_test_ch1))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ebf07a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "indices_0 = np.where(y_train == 0)[0]\n",
    "indices_1 = np.where(y_train == 1)[0]\n",
    "\n",
    "random_seed(42)\n",
    "random_indices_0 = np.random.choice(indices_0, size=250, replace=0)\n",
    "random_indices_1 = np.random.choice(indices_1, size=350, replace=0)\n",
    "random_indices = np.concatenate((random_indices_0, random_indices_1), axis=0)\n",
    "\n",
    "x_val_cxr = x_train_cxr[random_indices]\n",
    "x_val_ch0 = x_train_ch0[random_indices]\n",
    "x_val_ch1 = x_train_ch1[random_indices]\n",
    "y_val = y_train[random_indices]\n",
    "\n",
    "x_train_cxr = np.delete(x_train_cxr, random_indices, axis=0)\n",
    "x_train_ch0 = np.delete(x_train_ch0, random_indices, axis=0)\n",
    "x_train_ch1 = np.delete(x_train_ch1, random_indices, axis=0)\n",
    "y_train = np.delete(y_train, random_indices, axis=0)\n",
    "\n",
    "print(np.shape(x_train_cxr))\n",
    "print(np.shape(x_train_ch0))\n",
    "print(np.shape(x_train_ch1))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_val_cxr))\n",
    "print(np.shape(x_val_ch0))\n",
    "print(np.shape(x_val_ch1))\n",
    "print(np.shape(y_val))\n",
    "print(np.shape(x_test_cxr))\n",
    "print(np.shape(x_test_ch0))\n",
    "print(np.shape(x_test_ch1))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f07dfe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "x_train_cxr = x_train_cxr.reshape(-1, img_size, img_size)\n",
    "x_train_rgb_cxr = np.stack((x_train_cxr,) * 3, axis=-1)\n",
    "x_train_ch0 = x_train_ch0.reshape(-1, img_size, img_size)\n",
    "x_train_rgb_ch0 = np.stack((x_train_ch0,) * 3, axis=-1)\n",
    "x_train_ch1 = x_train_ch1.reshape(-1, img_size, img_size)\n",
    "x_train_rgb_ch1 = np.stack((x_train_ch1,) * 3, axis=-1)\n",
    "\n",
    "x_val_cxr = x_val_cxr.reshape(-1, img_size, img_size)\n",
    "x_val_rgb_cxr = np.stack((x_val_cxr,) * 3, axis=-1)\n",
    "x_val_ch0 = x_val_ch0.reshape(-1, img_size, img_size)\n",
    "x_val_rgb_ch0 = np.stack((x_val_ch0,) * 3, axis=-1)\n",
    "x_val_ch1 = x_val_ch1.reshape(-1, img_size, img_size)\n",
    "x_val_rgb_ch1 = np.stack((x_val_ch1,) * 3, axis=-1)\n",
    "\n",
    "x_test_cxr = x_test_cxr.reshape(-1, img_size, img_size)\n",
    "x_test_rgb_cxr = np.stack((x_test_cxr,) * 3, axis=-1)\n",
    "x_test_ch0 = x_test_ch0.reshape(-1, img_size, img_size)\n",
    "x_test_rgb_ch0 = np.stack((x_test_ch0,) * 3, axis=-1)\n",
    "x_test_ch1 = x_test_ch1.reshape(-1, img_size, img_size)\n",
    "x_test_rgb_ch1 = np.stack((x_test_ch1,) * 3, axis=-1)\n",
    "\n",
    "print(np.shape(x_train_rgb_cxr))\n",
    "print(np.shape(x_train_rgb_ch0))\n",
    "print(np.shape(x_train_rgb_ch1))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_val_rgb_cxr))\n",
    "print(np.shape(x_val_rgb_ch0))\n",
    "print(np.shape(x_val_rgb_ch1))\n",
    "print(np.shape(y_val))\n",
    "print(np.shape(x_test_rgb_cxr))\n",
    "print(np.shape(x_test_rgb_ch0))\n",
    "print(np.shape(x_test_rgb_ch1))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18647dc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "idx = 9\n",
    "plt.imshow(x_train_rgb_cxr[idx])\n",
    "plt.show()\n",
    "plt.imshow(x_train_rgb_ch0[idx], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(x_train_rgb_ch1[idx], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c982b4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(classes, class_weights)}\n",
    "\n",
    "print(class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b522db",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)\n",
    "\n",
    "print(np.shape(x_train_cxr))\n",
    "print(np.shape(x_train_ch0))\n",
    "print(np.shape(x_train_ch1))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_val_cxr))\n",
    "print(np.shape(x_val_ch0))\n",
    "print(np.shape(x_val_ch1))\n",
    "print(np.shape(y_val))\n",
    "print(np.shape(x_test_cxr))\n",
    "print(np.shape(x_test_ch0))\n",
    "print(np.shape(x_test_ch1))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae726e08",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "random_seed(42)\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "history_1 = model.fit(\n",
    "    x=x_train_rgb_cxr,\n",
    "    y=y_train,\n",
    "    validation_data=(x_val_rgb_cxr, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    if 'block5' in layer.name:\n",
    "        layer.trainable = True\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-6),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_2 = model.fit(\n",
    "    x=x_train_rgb_cxr,\n",
    "    y=y_train,\n",
    "    validation_data=(x_val_rgb_cxr, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "y_pred = model.predict(x_test_rgb_cxr, verbose=False)\n",
    "y_pred = np.argmax(y_pred, axis=1).reshape(-1)\n",
    "\n",
    "print('accuracy = {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('precision = {}'.format(precision_score(y_test, y_pred)))\n",
    "print('FDR = {}'.format(fdr(y_test, y_pred)))\n",
    "print('recall = {}'.format(recall_score(y_test, y_pred)))\n",
    "print('FNR = {}'.format(fnr(y_test, y_pred)))\n",
    "print('specificity = {}'.format(specificity(y_test, y_pred)))\n",
    "print('NPV = {}'.format(npv(y_test, y_pred)))\n",
    "print('f1-score = {}'.format(f1_score(y_test, y_pred)))\n",
    "print('AUC = {}'.format(roc_auc_score(y_test, y_pred)))\n",
    "print('MCC = {}'.format(matthews_corrcoef(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13228823",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "random_seed(42)\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "history_1 = model.fit(\n",
    "    x=x_train_rgb_ch0,\n",
    "    y=y_train,\n",
    "    validation_data=(x_val_rgb_ch0, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    if 'block5' in layer.name:\n",
    "        layer.trainable = True\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-6),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_2 = model.fit(\n",
    "    x=x_train_rgb_ch0,\n",
    "    y=y_train,\n",
    "    validation_data=(x_val_rgb_ch0, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "y_pred = model.predict(x_test_rgb_ch0, verbose=False)\n",
    "y_pred = np.argmax(y_pred, axis=1).reshape(-1)\n",
    "\n",
    "print('accuracy = {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('precision = {}'.format(precision_score(y_test, y_pred)))\n",
    "print('FDR = {}'.format(fdr(y_test, y_pred)))\n",
    "print('recall = {}'.format(recall_score(y_test, y_pred)))\n",
    "print('FNR = {}'.format(fnr(y_test, y_pred)))\n",
    "print('specificity = {}'.format(specificity(y_test, y_pred)))\n",
    "print('NPV = {}'.format(npv(y_test, y_pred)))\n",
    "print('f1-score = {}'.format(f1_score(y_test, y_pred)))\n",
    "print('AUC = {}'.format(roc_auc_score(y_test, y_pred)))\n",
    "print('MCC = {}'.format(matthews_corrcoef(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a529c40b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "random_seed(42)\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "history_1 = model.fit(\n",
    "    x=x_train_rgb_ch1,\n",
    "    y=y_train,\n",
    "    validation_data=(x_val_rgb_ch1, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    if 'block5' in layer.name:\n",
    "        layer.trainable = True\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-6),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_2 = model.fit(\n",
    "    x=x_train_rgb_ch1,\n",
    "    y=y_train,\n",
    "    validation_data=(x_val_rgb_ch1, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "y_pred = model.predict(x_test_rgb_ch1, verbose=False)\n",
    "y_pred = np.argmax(y_pred, axis=1).reshape(-1)\n",
    "\n",
    "print('accuracy = {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('precision = {}'.format(precision_score(y_test, y_pred)))\n",
    "print('FDR = {}'.format(fdr(y_test, y_pred)))\n",
    "print('recall = {}'.format(recall_score(y_test, y_pred)))\n",
    "print('FNR = {}'.format(fnr(y_test, y_pred)))\n",
    "print('specificity = {}'.format(specificity(y_test, y_pred)))\n",
    "print('NPV = {}'.format(npv(y_test, y_pred)))\n",
    "print('f1-score = {}'.format(f1_score(y_test, y_pred)))\n",
    "print('AUC = {}'.format(roc_auc_score(y_test, y_pred)))\n",
    "print('MCC = {}'.format(matthews_corrcoef(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
