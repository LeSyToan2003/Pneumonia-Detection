{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    keras.utils.set_random_seed(seed)\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = \"42\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **METRICS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fdr(y_true, y_pred):\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    \n",
    "    fdr_ = FP / (FP + TP) if (FP + TP) > 0 else 0\n",
    "    \n",
    "    return fdr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fnr(y_true, y_pred):\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    \n",
    "    fnr_ = FN / (FN + TP) if (FN + TP) > 0 else 0\n",
    "    \n",
    "    return fnr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def specificity(y_true, y_pred):\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    \n",
    "    specificity_ = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    \n",
    "    return specificity_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def npv(y_true, y_pred):\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    npv_ = TN / (TN + FN) if (TN + FN) > 0 else 0\n",
    "    \n",
    "    return npv_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_cxr = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/train/cxr.csv')\n",
    "train_ch0 = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/train/segment.csv')\n",
    "train_ch1 = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/train/segment_with_convexhull.csv')\n",
    "\n",
    "test_cxr = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/test/cxr.csv')\n",
    "test_ch0 = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/test/segment.csv')\n",
    "test_ch1 = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/test/segment_with_convexhull.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train_cxr = train_cxr.drop(['class'], axis=1).to_numpy()\n",
    "x_train_ch0 = train_ch0.drop(['class'], axis=1).to_numpy()\n",
    "x_train_ch1 = train_ch1.drop(['class'], axis=1).to_numpy()\n",
    "y_train = train_cxr['class'].to_numpy()\n",
    "\n",
    "x_test_cxr = test_cxr.drop(['class'], axis=1).to_numpy()\n",
    "x_test_ch0 = test_ch0.drop(['class'], axis=1).to_numpy()\n",
    "x_test_ch1 = test_ch1.drop(['class'], axis=1).to_numpy()\n",
    "y_test = test_cxr['class'].to_numpy()\n",
    "\n",
    "print(np.shape(x_train_cxr))\n",
    "print(np.shape(x_train_ch0))\n",
    "print(np.shape(x_train_ch1))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_test_cxr))\n",
    "print(np.shape(x_test_ch0))\n",
    "print(np.shape(x_test_ch1))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(classes, class_weights)}\n",
    "\n",
    "print(class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LOGISTIC REGRESSION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CXR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "random_seed(42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_iter': [50, 100, 150, 200, 250, 300],\n",
    "    'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "param_list = list(ParameterGrid(param_grid))\n",
    "\n",
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "for i in tqdm(range(len(param_list))):\n",
    "    params = param_list[i]\n",
    "    clf = LogisticRegression(**params, class_weight=class_weight_dict, random_state=42)\n",
    "    clf.fit(x_train_cxr, y_train)\n",
    "    score = clf.score(x_test_cxr, y_test)\n",
    "    print('{}: {}'.format(params, score))\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(\n",
    "    C=0.05,\n",
    "    max_iter=50,\n",
    "    penalty='l2',\n",
    "    solver='saga',\n",
    "    class_weight=class_weight_dict,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf.fit(x_train_cxr, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test_cxr)\n",
    "\n",
    "print('accuracy = {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('precision = {}'.format(precision_score(y_test, y_pred)))\n",
    "print('FDR = {}'.format(fdr(y_test, y_pred)))\n",
    "print('recall = {}'.format(recall_score(y_test, y_pred)))\n",
    "print('FNR = {}'.format(fnr(y_test, y_pred)))\n",
    "print('specificity = {}'.format(specificity(y_test, y_pred)))\n",
    "print('NPV = {}'.format(npv(y_test, y_pred)))\n",
    "print('f1-score = {}'.format(f1_score(y_test, y_pred)))\n",
    "print('AUC = {}'.format(roc_auc_score(y_test, y_pred)))\n",
    "print('MCC = {}'.format(matthews_corrcoef(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CH0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "random_seed(42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_iter': [50, 100, 150, 200, 250, 300],\n",
    "    'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "param_list = list(ParameterGrid(param_grid))\n",
    "\n",
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "for i in tqdm(range(len(param_list))):\n",
    "    params = param_list[i]\n",
    "    clf = LogisticRegression(**params, class_weight=class_weight_dict, random_state=42)\n",
    "    clf.fit(x_train_ch0, y_train)\n",
    "    score = clf.score(x_test_ch0, y_test)\n",
    "    print('{}: {}'.format(params, score))\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(\n",
    "    C=0.5,\n",
    "    max_iter=200,\n",
    "    penalty='l1',\n",
    "    solver='saga',\n",
    "    class_weight=class_weight_dict,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf.fit(x_train_ch0, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test_ch0)\n",
    "\n",
    "print('accuracy = {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('precision = {}'.format(precision_score(y_test, y_pred)))\n",
    "print('FDR = {}'.format(fdr(y_test, y_pred)))\n",
    "print('recall = {}'.format(recall_score(y_test, y_pred)))\n",
    "print('FNR = {}'.format(fnr(y_test, y_pred)))\n",
    "print('specificity = {}'.format(specificity(y_test, y_pred)))\n",
    "print('NPV = {}'.format(npv(y_test, y_pred)))\n",
    "print('f1-score = {}'.format(f1_score(y_test, y_pred)))\n",
    "print('AUC = {}'.format(roc_auc_score(y_test, y_pred)))\n",
    "print('MCC = {}'.format(matthews_corrcoef(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CH1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "random_seed(42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_iter': [50, 100, 150, 200, 250, 300],\n",
    "    'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "param_list = list(ParameterGrid(param_grid))\n",
    "\n",
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "for i in tqdm(range(len(param_list))):\n",
    "    params = param_list[i]\n",
    "    clf = LogisticRegression(**params, class_weight=class_weight_dict, random_state=42)\n",
    "    clf.fit(x_train_ch1, y_train)\n",
    "    score = clf.score(x_test_ch1, y_test)\n",
    "    print('{}: {}'.format(params, score))\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(\n",
    "    C=0.1,\n",
    "    max_iter=50,\n",
    "    penalty='l2',\n",
    "    solver='saga',\n",
    "    class_weight=class_weight_dict,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf.fit(x_train_ch1, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test_ch1)\n",
    "\n",
    "print('accuracy = {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('precision = {}'.format(precision_score(y_test, y_pred)))\n",
    "print('FDR = {}'.format(fdr(y_test, y_pred)))\n",
    "print('recall = {}'.format(recall_score(y_test, y_pred)))\n",
    "print('FNR = {}'.format(fnr(y_test, y_pred)))\n",
    "print('specificity = {}'.format(specificity(y_test, y_pred)))\n",
    "print('NPV = {}'.format(npv(y_test, y_pred)))\n",
    "print('f1-score = {}'.format(f1_score(y_test, y_pred)))\n",
    "print('AUC = {}'.format(roc_auc_score(y_test, y_pred)))\n",
    "print('MCC = {}'.format(matthews_corrcoef(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6839424,
     "isSourceIdPinned": true,
     "sourceId": 11016846,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
