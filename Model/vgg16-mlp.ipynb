{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LIBRARIES IMPORTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import zipfile\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import InputLayer, Conv2D, MaxPool2D\n",
    "from keras.layers import Flatten, GlobalAveragePooling2D, GlobalMaxPooling2D, Concatenate\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.saving import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    keras.utils.set_random_seed(seed)\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = \"42\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **METRICS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fdr(y_true, y_pred):\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    \n",
    "    fdr_ = FP / (FP + TP) if (FP + TP) > 0 else 0\n",
    "    \n",
    "    return fdr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fnr(y_true, y_pred):\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    \n",
    "    fnr_ = FN / (FN + TP) if (FN + TP) > 0 else 0\n",
    "    \n",
    "    return fnr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def specificity(y_true, y_pred):\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    \n",
    "    specificity_ = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    \n",
    "    return specificity_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def npv(y_true, y_pred):\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    npv_ = TN / (TN + FN) if (TN + FN) > 0 else 0\n",
    "    \n",
    "    return npv_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_cxr = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/train/cxr.csv')\n",
    "train_ch0 = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/train/segment.csv')\n",
    "train_ch1 = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/train/segment_with_convexhull.csv')\n",
    "\n",
    "test_cxr = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/test/cxr.csv')\n",
    "test_ch0 = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/test/segment.csv')\n",
    "test_ch1 = pd.read_csv('/kaggle/input/pneumonia-detection-features-datasets/test/segment_with_convexhull.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train_cxr = train_cxr.drop(['class'], axis=1).to_numpy()\n",
    "x_train_ch0 = train_ch0.drop(['class'], axis=1).to_numpy()\n",
    "x_train_ch1 = train_ch1.drop(['class'], axis=1).to_numpy()\n",
    "y_train = train_cxr['class'].to_numpy()\n",
    "\n",
    "x_test_cxr = test_cxr.drop(['class'], axis=1).to_numpy()\n",
    "x_test_ch0 = test_ch0.drop(['class'], axis=1).to_numpy()\n",
    "x_test_ch1 = test_ch1.drop(['class'], axis=1).to_numpy()\n",
    "y_test = test_cxr['class'].to_numpy()\n",
    "\n",
    "print(np.shape(x_train_cxr))\n",
    "print(np.shape(x_train_ch0))\n",
    "print(np.shape(x_train_ch1))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_test_cxr))\n",
    "print(np.shape(x_test_ch0))\n",
    "print(np.shape(x_test_ch1))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "indices_0 = np.where(y_train == 0)[0]\n",
    "indices_1 = np.where(y_train == 1)[0]\n",
    "\n",
    "random_seed(42)\n",
    "random_indices_0 = np.random.choice(indices_0, size=250, replace=0)\n",
    "random_indices_1 = np.random.choice(indices_1, size=350, replace=0)\n",
    "random_indices = np.concatenate((random_indices_0, random_indices_1), axis=0)\n",
    "\n",
    "x_val_cxr = x_train_cxr[random_indices]\n",
    "x_val_ch0 = x_train_ch0[random_indices]\n",
    "x_val_ch1 = x_train_ch1[random_indices]\n",
    "y_val = y_train[random_indices]\n",
    "\n",
    "x_train_cxr = np.delete(x_train_cxr, random_indices, axis=0)\n",
    "x_train_ch0 = np.delete(x_train_ch0, random_indices, axis=0)\n",
    "x_train_ch1 = np.delete(x_train_ch1, random_indices, axis=0)\n",
    "y_train = np.delete(y_train, random_indices, axis=0)\n",
    "\n",
    "print(np.shape(x_train_cxr))\n",
    "print(np.shape(x_train_ch0))\n",
    "print(np.shape(x_train_ch1))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_val_cxr))\n",
    "print(np.shape(x_val_ch0))\n",
    "print(np.shape(x_val_ch1))\n",
    "print(np.shape(y_val))\n",
    "print(np.shape(x_test_cxr))\n",
    "print(np.shape(x_test_ch0))\n",
    "print(np.shape(x_test_ch1))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(classes, class_weights)}\n",
    "\n",
    "print(class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)\n",
    "\n",
    "print(np.shape(x_train_cxr))\n",
    "print(np.shape(x_train_ch0))\n",
    "print(np.shape(x_train_ch1))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_val_cxr))\n",
    "print(np.shape(x_val_ch0))\n",
    "print(np.shape(x_val_ch1))\n",
    "print(np.shape(y_val))\n",
    "print(np.shape(x_test_cxr))\n",
    "print(np.shape(x_test_ch0))\n",
    "print(np.shape(x_test_ch1))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MLP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CXR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "random_seed(42)\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(shape=(8192,)),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=4e-6),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=10, \n",
    "    restore_best_weights=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train_cxr, \n",
    "    y=y_train,\n",
    "    validation_data=(x_val_cxr, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "y_pred = model.predict(x_test_cxr, verbose=False)\n",
    "y_pred = np.argmax(y_pred, axis=1).reshape(-1)\n",
    "\n",
    "print('accuracy = {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('precision = {}'.format(precision_score(y_test, y_pred)))\n",
    "print('FDR = {}'.format(fdr(y_test, y_pred)))\n",
    "print('recall = {}'.format(recall_score(y_test, y_pred)))\n",
    "print('FNR = {}'.format(fnr(y_test, y_pred)))\n",
    "print('specificity = {}'.format(specificity(y_test, y_pred)))\n",
    "print('NPV = {}'.format(npv(y_test, y_pred)))\n",
    "print('f1-score = {}'.format(f1_score(y_test, y_pred)))\n",
    "print('AUC = {}'.format(roc_auc_score(y_test, y_pred)))\n",
    "print('MCC = {}'.format(matthews_corrcoef(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CH0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "random_seed(42)\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(shape=(8192,)),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=4e-6),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=10, \n",
    "    restore_best_weights=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train_ch0, \n",
    "    y=y_train,\n",
    "    validation_data=(x_val_ch0, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "y_pred = model.predict(x_test_ch0, verbose=False)\n",
    "y_pred = np.argmax(y_pred, axis=1).reshape(-1)\n",
    "\n",
    "print('accuracy = {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('precision = {}'.format(precision_score(y_test, y_pred)))\n",
    "print('FDR = {}'.format(fdr(y_test, y_pred)))\n",
    "print('recall = {}'.format(recall_score(y_test, y_pred)))\n",
    "print('FNR = {}'.format(fnr(y_test, y_pred)))\n",
    "print('specificity = {}'.format(specificity(y_test, y_pred)))\n",
    "print('NPV = {}'.format(npv(y_test, y_pred)))\n",
    "print('f1-score = {}'.format(f1_score(y_test, y_pred)))\n",
    "print('AUC = {}'.format(roc_auc_score(y_test, y_pred)))\n",
    "print('MCC = {}'.format(matthews_corrcoef(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CH1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "random_seed(42)\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(shape=(8192,)),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=4e-6),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=10, \n",
    "    restore_best_weights=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train_ch1, \n",
    "    y=y_train,\n",
    "    validation_data=(x_val_ch1, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "y_pred = model.predict(x_test_ch1, verbose=False)\n",
    "y_pred = np.argmax(y_pred, axis=1).reshape(-1)\n",
    "\n",
    "print('accuracy = {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('precision = {}'.format(precision_score(y_test, y_pred)))\n",
    "print('FDR = {}'.format(fdr(y_test, y_pred)))\n",
    "print('recall = {}'.format(recall_score(y_test, y_pred)))\n",
    "print('FNR = {}'.format(fnr(y_test, y_pred)))\n",
    "print('specificity = {}'.format(specificity(y_test, y_pred)))\n",
    "print('NPV = {}'.format(npv(y_test, y_pred)))\n",
    "print('f1-score = {}'.format(f1_score(y_test, y_pred)))\n",
    "print('AUC = {}'.format(roc_auc_score(y_test, y_pred)))\n",
    "print('MCC = {}'.format(matthews_corrcoef(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model.save('/kaggle/working/model.h5')\n",
    "\n",
    "# with open('history.pkl', 'wb') as f:\n",
    "#     pickle.dump(history.history, f)\n",
    "\n",
    "# with zipfile.ZipFile('model.zip', 'w') as zipf:\n",
    "#     zipf.write('model.h5')\n",
    "#     zipf.write('history.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !rm -rf /kaggle/working/*"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6839424,
     "isSourceIdPinned": true,
     "sourceId": 11016846,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
