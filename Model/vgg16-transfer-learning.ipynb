{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11016736,"sourceType":"datasetVersion","datasetId":6697966,"isSourceIdPinned":true}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **LIBRARIES**","metadata":{}},{"cell_type":"code","source":"import os\nimport pickle\nimport zipfile\nimport random\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport keras\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\nfrom keras.utils import to_categorical\nfrom keras.applications import VGG16\nfrom keras import Sequential\nfrom keras.models import Model\nfrom keras.layers import InputLayer, Flatten, Dense, Dropout, BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom keras.saving import load_model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def random_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    keras.utils.set_random_seed(seed)\n\n    os.environ[\"PYTHONHASHSEED\"] = \"42\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"random_seed(42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **METRICS**","metadata":{}},{"cell_type":"code","source":"def fdr(y_true, y_pred):\n    FP = np.sum((y_true == 0) & (y_pred == 1))\n    TP = np.sum((y_true == 1) & (y_pred == 1))\n    \n    fdr_ = FP / (FP + TP) if (FP + TP) > 0 else 0\n    \n    return fdr_","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fnr(y_true, y_pred):\n    FN = np.sum((y_true == 1) & (y_pred == 0))\n    TP = np.sum((y_true == 1) & (y_pred == 1))\n    \n    fnr_ = FN / (FN + TP) if (FN + TP) > 0 else 0\n    \n    return fnr_","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def specificity(y_true, y_pred):\n    TN = np.sum((y_true == 0) & (y_pred == 0))\n    FP = np.sum((y_true == 0) & (y_pred == 1))\n    \n    specificity_ = TN / (TN + FP) if (TN + FP) > 0 else 0\n    \n    return specificity_","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def npv(y_true, y_pred):\n    TN = np.sum((y_true == 0) & (y_pred == 0))\n    FN = np.sum((y_true == 1) & (y_pred == 0))\n    \n    npv_ = TN / (TN + FN) if (TN + FN) > 0 else 0\n    \n    return npv_","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **DATASET**","metadata":{}},{"cell_type":"code","source":"img_size = 128","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train_cxr = np.load('/kaggle/input/pneumonia-detection-datasets/chest-xray/train/images.npy')\nx_train_ch0 = np.load('/kaggle/input/pneumonia-detection-datasets/segment/train/images.npy')\nx_train_ch1 = np.load('/kaggle/input/pneumonia-detection-datasets/segment_with_convexhull/train/images.npy')\ny_train = np.load('/kaggle/input/pneumonia-detection-datasets/chest-xray/train/labels.npy')\n\nx_test_cxr = np.load('/kaggle/input/pneumonia-detection-datasets/chest-xray/test/images.npy')\nx_test_ch0 = np.load('/kaggle/input/pneumonia-detection-datasets/segment/test/images.npy')\nx_test_ch1 = np.load('/kaggle/input/pneumonia-detection-datasets/segment_with_convexhull/test/images.npy')\ny_test = np.load('/kaggle/input/pneumonia-detection-datasets/chest-xray/test/labels.npy')\n\nprint(np.shape(x_train_cxr))\nprint(np.shape(x_train_ch0))\nprint(np.shape(x_train_ch1))\nprint(np.shape(y_train))\nprint(np.shape(x_test_cxr))\nprint(np.shape(x_test_ch0))\nprint(np.shape(x_test_ch1))\nprint(np.shape(y_test))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"indices_0 = np.where(y_train == 0)[0]\nindices_1 = np.where(y_train == 1)[0]\n\nrandom_seed(42)\nrandom_indices_0 = np.random.choice(indices_0, size=250, replace=0)\nrandom_indices_1 = np.random.choice(indices_1, size=350, replace=0)\nrandom_indices = np.concatenate((random_indices_0, random_indices_1), axis=0)\n\nx_val_cxr = x_train_cxr[random_indices]\nx_val_ch0 = x_train_ch0[random_indices]\nx_val_ch1 = x_train_ch1[random_indices]\ny_val = y_train[random_indices]\n\nx_train_cxr = np.delete(x_train_cxr, random_indices, axis=0)\nx_train_ch0 = np.delete(x_train_ch0, random_indices, axis=0)\nx_train_ch1 = np.delete(x_train_ch1, random_indices, axis=0)\ny_train = np.delete(y_train, random_indices, axis=0)\n\nprint(np.shape(x_train_cxr))\nprint(np.shape(x_train_ch0))\nprint(np.shape(x_train_ch1))\nprint(np.shape(y_train))\nprint(np.shape(x_val_cxr))\nprint(np.shape(x_val_ch0))\nprint(np.shape(x_val_ch1))\nprint(np.shape(y_val))\nprint(np.shape(x_test_cxr))\nprint(np.shape(x_test_ch0))\nprint(np.shape(x_test_ch1))\nprint(np.shape(y_test))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train_cxr = x_train_cxr.reshape(-1, img_size, img_size)\nx_train_rgb_cxr = np.stack((x_train_cxr,) * 3, axis=-1)\nx_train_ch0 = x_train_ch0.reshape(-1, img_size, img_size)\nx_train_rgb_ch0 = np.stack((x_train_ch0,) * 3, axis=-1)\nx_train_ch1 = x_train_ch1.reshape(-1, img_size, img_size)\nx_train_rgb_ch1 = np.stack((x_train_ch1,) * 3, axis=-1)\n\nx_val_cxr = x_val_cxr.reshape(-1, img_size, img_size)\nx_val_rgb_cxr = np.stack((x_val_cxr,) * 3, axis=-1)\nx_val_ch0 = x_val_ch0.reshape(-1, img_size, img_size)\nx_val_rgb_ch0 = np.stack((x_val_ch0,) * 3, axis=-1)\nx_val_ch1 = x_val_ch1.reshape(-1, img_size, img_size)\nx_val_rgb_ch1 = np.stack((x_val_ch1,) * 3, axis=-1)\n\nx_test_cxr = x_test_cxr.reshape(-1, img_size, img_size)\nx_test_rgb_cxr = np.stack((x_test_cxr,) * 3, axis=-1)\nx_test_ch0 = x_test_ch0.reshape(-1, img_size, img_size)\nx_test_rgb_ch0 = np.stack((x_test_ch0,) * 3, axis=-1)\nx_test_ch1 = x_test_ch1.reshape(-1, img_size, img_size)\nx_test_rgb_ch1 = np.stack((x_test_ch1,) * 3, axis=-1)\n\nprint(np.shape(x_train_rgb_cxr))\nprint(np.shape(x_train_rgb_ch0))\nprint(np.shape(x_train_rgb_ch1))\nprint(np.shape(y_train))\nprint(np.shape(x_val_rgb_cxr))\nprint(np.shape(x_val_rgb_ch0))\nprint(np.shape(x_val_rgb_ch1))\nprint(np.shape(y_val))\nprint(np.shape(x_test_rgb_cxr))\nprint(np.shape(x_test_rgb_ch0))\nprint(np.shape(x_test_rgb_ch1))\nprint(np.shape(y_test))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"idx = 9\nplt.imshow(x_train_rgb_cxr[idx])\nplt.show()\nplt.imshow(x_train_rgb_ch0[idx], cmap='gray')\nplt.show()\nplt.imshow(x_train_rgb_ch1[idx], cmap='gray')\nplt.show()","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classes = np.unique(y_train)\nclass_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n\nclass_weight_dict = {cls: weight for cls, weight in zip(classes, class_weights)}\n\nprint(class_weight_dict)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train = to_categorical(y_train, num_classes=2)\ny_val = to_categorical(y_val, num_classes=2)\n\nprint(np.shape(x_train_cxr))\nprint(np.shape(x_train_ch0))\nprint(np.shape(x_train_ch1))\nprint(np.shape(y_train))\nprint(np.shape(x_val_cxr))\nprint(np.shape(x_val_ch0))\nprint(np.shape(x_val_ch1))\nprint(np.shape(y_val))\nprint(np.shape(x_test_cxr))\nprint(np.shape(x_test_ch0))\nprint(np.shape(x_test_ch1))\nprint(np.shape(y_test))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **VGG16**","metadata":{}},{"cell_type":"code","source":"# base_model = VGG16(weights='imagenet', include_top=True, input_shape=(128, 128, 3))\n# base_model.summary()\n# for i, layer in enumerate(base_model.layers):\n#    print(i, layer.name, layer.trainable)","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **CXR**","metadata":{}},{"cell_type":"code","source":"random_seed(42)\n\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\nbase_model.trainable = False\n\nx = Flatten()(base_model.output)\n\nx = Dense(256, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Dense(128, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Dense(2, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=x)\n\nmodel.compile(optimizer=Adam(learning_rate=4e-6),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# model.summary()\n\nearly_stopping = EarlyStopping(\n    monitor=\"val_accuracy\",\n    patience=10, \n    restore_best_weights=True,\n    verbose=True\n)\n\nhistory_1 = model.fit(\n    x=x_train_rgb_cxr,\n    y=y_train,\n    validation_data=(x_val_rgb_cxr, y_val),\n    batch_size=32,\n    epochs=50,\n    class_weight=class_weight_dict,\n    callbacks=[early_stopping]\n)\n\nfor layer in base_model.layers: \n    layer.trainable = True\n\n# model.summary()\n\nmodel.compile(optimizer=Adam(learning_rate=1e-6),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nearly_stopping = EarlyStopping(\n    monitor=\"val_accuracy\",\n    patience=10, \n    restore_best_weights=True,\n    verbose=True\n)\n\nhistory_2 = model.fit(\n    x=x_train_rgb_cxr,\n    y=y_train,\n    validation_data=(x_val_rgb_cxr, y_val),\n    batch_size=32,\n    epochs=50,\n    class_weight=class_weight_dict,\n    callbacks=[early_stopping]\n)\n\ny_pred = model.predict(x_test_rgb_cxr, verbose=False)\ny_pred = np.argmax(y_pred, axis=1).reshape(-1)\n\nprint('accuracy = {}'.format(accuracy_score(y_test, y_pred)))\nprint('precision = {}'.format(precision_score(y_test, y_pred)))\nprint('FDR = {}'.format(fdr(y_test, y_pred)))\nprint('recall = {}'.format(recall_score(y_test, y_pred)))\nprint('FNR = {}'.format(fnr(y_test, y_pred)))\nprint('specificity = {}'.format(specificity(y_test, y_pred)))\nprint('NPV = {}'.format(npv(y_test, y_pred)))\nprint('f1-score = {}'.format(f1_score(y_test, y_pred)))\nprint('AUC = {}'.format(roc_auc_score(y_test, y_pred)))\nprint('MCC = {}'.format(matthews_corrcoef(y_test, y_pred)))","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **CH0**","metadata":{}},{"cell_type":"code","source":"random_seed(42)\n\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\nbase_model.trainable = False\n\nx = Flatten()(base_model.output)\n\nx = Dense(256, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Dense(128, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Dense(2, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=x)\n\nmodel.compile(optimizer=Adam(learning_rate=4e-6),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# model.summary()\n\nearly_stopping = EarlyStopping(\n    monitor=\"val_accuracy\",\n    patience=10, \n    restore_best_weights=True,\n    verbose=True\n)\n\nhistory_1 = model.fit(\n    x=x_train_rgb_ch0,\n    y=y_train,\n    validation_data=(x_val_rgb_ch0, y_val),\n    batch_size=32,\n    epochs=50,\n    class_weight=class_weight_dict,\n    callbacks=[early_stopping]\n)\n\nfor layer in base_model.layers: \n    layer.trainable = True\n\n# model.summary()\n\nmodel.compile(optimizer=Adam(learning_rate=1e-6),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nearly_stopping = EarlyStopping(\n    monitor=\"val_accuracy\",\n    patience=10, \n    restore_best_weights=True,\n    verbose=True\n)\n\nhistory_2 = model.fit(\n    x=x_train_rgb_ch0,\n    y=y_train,\n    validation_data=(x_val_rgb_ch0, y_val),\n    batch_size=32,\n    epochs=50,\n    class_weight=class_weight_dict,\n    callbacks=[early_stopping]\n)\n\ny_pred = model.predict(x_test_rgb_ch0, verbose=False)\ny_pred = np.argmax(y_pred, axis=1).reshape(-1)\n\nprint('accuracy = {}'.format(accuracy_score(y_test, y_pred)))\nprint('precision = {}'.format(precision_score(y_test, y_pred)))\nprint('FDR = {}'.format(fdr(y_test, y_pred)))\nprint('recall = {}'.format(recall_score(y_test, y_pred)))\nprint('FNR = {}'.format(fnr(y_test, y_pred)))\nprint('specificity = {}'.format(specificity(y_test, y_pred)))\nprint('NPV = {}'.format(npv(y_test, y_pred)))\nprint('f1-score = {}'.format(f1_score(y_test, y_pred)))\nprint('AUC = {}'.format(roc_auc_score(y_test, y_pred)))\nprint('MCC = {}'.format(matthews_corrcoef(y_test, y_pred)))","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **CH1**","metadata":{}},{"cell_type":"code","source":"random_seed(42)\n\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\nbase_model.trainable = False\n\nx = Flatten()(base_model.output)\n\nx = Dense(256, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Dense(128, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Dense(2, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=x)\n\nmodel.compile(optimizer=Adam(learning_rate=4e-6),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# model.summary()\n\nearly_stopping = EarlyStopping(\n    monitor=\"val_accuracy\",\n    patience=10, \n    restore_best_weights=True,\n    verbose=True\n)\n\nhistory_1 = model.fit(\n    x=x_train_rgb_ch1,\n    y=y_train,\n    validation_data=(x_val_rgb_ch1, y_val),\n    batch_size=32,\n    epochs=50,\n    class_weight=class_weight_dict,\n    callbacks=[early_stopping]\n)\n\nfor layer in base_model.layers: \n    layer.trainable = True\n\n# model.summary()\n\nmodel.compile(optimizer=Adam(learning_rate=1e-6),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nearly_stopping = EarlyStopping(\n    monitor=\"val_accuracy\",\n    patience=10, \n    restore_best_weights=True,\n    verbose=True\n)\n\nhistory_2 = model.fit(\n    x=x_train_rgb_ch1,\n    y=y_train,\n    validation_data=(x_val_rgb_ch1, y_val),\n    batch_size=32,\n    epochs=50,\n    class_weight=class_weight_dict,\n    callbacks=[early_stopping]\n)\n\ny_pred = model.predict(x_test_rgb_ch1, verbose=False)\ny_pred = np.argmax(y_pred, axis=1).reshape(-1)\n\nprint('accuracy = {}'.format(accuracy_score(y_test, y_pred)))\nprint('precision = {}'.format(precision_score(y_test, y_pred)))\nprint('FDR = {}'.format(fdr(y_test, y_pred)))\nprint('recall = {}'.format(recall_score(y_test, y_pred)))\nprint('FNR = {}'.format(fnr(y_test, y_pred)))\nprint('specificity = {}'.format(specificity(y_test, y_pred)))\nprint('NPV = {}'.format(npv(y_test, y_pred)))\nprint('f1-score = {}'.format(f1_score(y_test, y_pred)))\nprint('AUC = {}'.format(roc_auc_score(y_test, y_pred)))\nprint('MCC = {}'.format(matthews_corrcoef(y_test, y_pred)))","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model.save('/kaggle/working/model.h5')\n\n# with open('history_1.pkl', 'wb') as f:\n#     pickle.dump(history_1.history, f)\n\n# with open('history_2.pkl', 'wb') as f:\n#     pickle.dump(history_2.history, f)\n\n# with zipfile.ZipFile('model.zip', 'w') as zipf:\n#     zipf.write('model.h5')\n#     zipf.write('history_1.pkl')\n#     zipf.write('history_2.pkl')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !rm -rf /kaggle/working/*","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}